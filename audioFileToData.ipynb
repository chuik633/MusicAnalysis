{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Data Processing\n",
    "### Goal: take a .wav file as input => get a list of features corresponding to emotion dataset\n",
    "(I want to make more data using existing files that matches the features I trained the emotion detecting model on and see how it does)\n",
    "\n",
    "--- \n",
    "\n",
    "feature names - for each feature they computed the mean of the mean, mean of the std, std of the mean, and std of the std. I am assuming the inner computation is for that window size.\n",
    "\n",
    "For example: \n",
    "- Mean_Acc1298_Mean_Mem40_Centroid numeric \n",
    "- Mean_Acc1298_Std_Mem40_Centroid numeric\n",
    "- Std_Acc1298_Mean_Mem40_Centroid numeric\n",
    "- Std_Acc1298_Std_Mem40_Centroid numeric\n",
    "\n",
    "\n",
    "They do this for the following features:\n",
    "1. Centroid (assuming this is the spectral centroid)\n",
    "2. Rolloff\n",
    "3. Flux\n",
    "4. MFCC constants 1-12\n",
    "\n",
    "I hope to do this and then plot the distributions to make sure that they fall into a similar distribution/range as the training data did (incase im accidentally scaling/not scaling something etc.)\n",
    "other assumptions: i'm assuming the Mem40 means that the window size for the inner aggregation is 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "#windowsize\n",
    "mem_size = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Centroid', 'Rolloff', 'Flux', 'MFCC_0', 'MFCC_1', 'MFCC_2', 'MFCC_3', 'MFCC_4', 'MFCC_5', 'MFCC_6', 'MFCC_7', 'MFCC_8', 'MFCC_9', 'MFCC_10', 'MFCC_11', 'MFCC_12']\n"
     ]
    }
   ],
   "source": [
    "feature_names = ['Centroid', 'Rolloff', 'Flux']\n",
    "for i in range(0,13):\n",
    "    feature_names.append(\"MFCC_\"+str(i))\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centroid\n",
    "y, sr = librosa.load(\"./data/movie_music/1.wav\")\n",
    "centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "rolloffs = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)[0]\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "S = np.abs(librosa.stft(y))\n",
    "S_norm = librosa.util.normalize(S, axis=0)\n",
    "flux = np.sqrt(np.sum(np.diff(S_norm, axis=1)**2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1445,)\n",
      "(1445,)\n",
      "(1445,)\n",
      "(13, 1445)\n",
      "(1444,)\n"
     ]
    }
   ],
   "source": [
    "print(centroids.shape)\n",
    "print(rolloffs.shape)\n",
    "print(mfccs[i].shape)\n",
    "print(mfccs.shape)\n",
    "print(flux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mean_Acc1298_Mean_Mem40_MFCC_12': -7.353248596191406, 'Mean_Acc1298_Std_Mem40_MFCC_12': 5.891010284423828, 'Std_Acc1298_Mean_Mem40_MFCC_12': 4.079969882965088, 'Std_Acc1298_Std_Mem40_MFCC_12': 1.3373233079910278, 'Mean_Acc1298_Mean_Mem40_MFCC_11': 2.949770927429199, 'Mean_Acc1298_Std_Mem40_MFCC_11': 5.783247947692871, 'Std_Acc1298_Mean_Mem40_MFCC_11': 5.9295268058776855, 'Std_Acc1298_Std_Mem40_MFCC_11': 1.0910663604736328, 'Mean_Acc1298_Mean_Mem40_MFCC_10': 6.195117473602295, 'Mean_Acc1298_Std_Mem40_MFCC_10': 5.600480079650879, 'Std_Acc1298_Mean_Mem40_MFCC_10': 3.6627042293548584, 'Std_Acc1298_Std_Mem40_MFCC_10': 0.9604876637458801, 'Mean_Acc1298_Mean_Mem40_MFCC_9': 11.387118339538574, 'Mean_Acc1298_Std_Mem40_MFCC_9': 6.32328987121582, 'Std_Acc1298_Mean_Mem40_MFCC_9': 3.769984722137451, 'Std_Acc1298_Std_Mem40_MFCC_9': 1.074137806892395, 'Mean_Acc1298_Mean_Mem40_MFCC_8': -2.333993911743164, 'Mean_Acc1298_Std_Mem40_MFCC_8': 5.693330764770508, 'Std_Acc1298_Mean_Mem40_MFCC_8': 2.6674866676330566, 'Std_Acc1298_Std_Mem40_MFCC_8': 1.1161398887634277, 'Mean_Acc1298_Mean_Mem40_MFCC_7': 3.1071341037750244, 'Mean_Acc1298_Std_Mem40_MFCC_7': 6.191984176635742, 'Std_Acc1298_Mean_Mem40_MFCC_7': 4.789244174957275, 'Std_Acc1298_Std_Mem40_MFCC_7': 0.8878383636474609, 'Mean_Acc1298_Mean_Mem40_MFCC_6': -0.807989239692688, 'Mean_Acc1298_Std_Mem40_MFCC_6': 6.239986896514893, 'Std_Acc1298_Mean_Mem40_MFCC_6': 3.5618298053741455, 'Std_Acc1298_Std_Mem40_MFCC_6': 1.1169005632400513, 'Mean_Acc1298_Mean_Mem40_MFCC_5': 16.96916961669922, 'Mean_Acc1298_Std_Mem40_MFCC_5': 5.348440170288086, 'Std_Acc1298_Mean_Mem40_MFCC_5': 4.2451558113098145, 'Std_Acc1298_Std_Mem40_MFCC_5': 1.6310641765594482, 'Mean_Acc1298_Mean_Mem40_MFCC_4': 3.2444465160369873, 'Mean_Acc1298_Std_Mem40_MFCC_4': 6.7707295417785645, 'Std_Acc1298_Mean_Mem40_MFCC_4': 5.707595348358154, 'Std_Acc1298_Std_Mem40_MFCC_4': 1.7199501991271973, 'Mean_Acc1298_Mean_Mem40_MFCC_3': 39.82611846923828, 'Mean_Acc1298_Std_Mem40_MFCC_3': 9.790545463562012, 'Std_Acc1298_Mean_Mem40_MFCC_3': 6.605585098266602, 'Std_Acc1298_Std_Mem40_MFCC_3': 1.944642424583435, 'Mean_Acc1298_Mean_Mem40_MFCC_2': -3.0486230850219727, 'Mean_Acc1298_Std_Mem40_MFCC_2': 12.937281608581543, 'Std_Acc1298_Mean_Mem40_MFCC_2': 14.240056037902832, 'Std_Acc1298_Std_Mem40_MFCC_2': 2.6926302909851074, 'Mean_Acc1298_Mean_Mem40_MFCC_1': 136.90609741210938, 'Mean_Acc1298_Std_Mem40_MFCC_1': 19.688255310058594, 'Std_Acc1298_Mean_Mem40_MFCC_1': 8.629405975341797, 'Std_Acc1298_Std_Mem40_MFCC_1': 4.888838291168213, 'Mean_Acc1298_Mean_Mem40_MFCC_0': -64.56968688964844, 'Mean_Acc1298_Std_Mem40_MFCC_0': 31.700809478759766, 'Std_Acc1298_Mean_Mem40_MFCC_0': 22.431238174438477, 'Std_Acc1298_Std_Mem40_MFCC_0': 7.305980205535889, 'Mean_Acc1298_Mean_Mem40_Centroid': 1387.5802726561644, 'Mean_Acc1298_Std_Mem40_Centroid': 315.4250222365572, 'Std_Acc1298_Mean_Mem40_Centroid': 150.1291933593075, 'Std_Acc1298_Std_Mem40_Centroid': 128.2821215276327, 'Mean_Acc1298_Mean_Mem40_Rolloff': 3008.7118530273438, 'Mean_Acc1298_Std_Mem40_Rolloff': 932.5448495330849, 'Std_Acc1298_Mean_Mem40_Rolloff': 380.3704021480624, 'Std_Acc1298_Std_Mem40_Rolloff': 394.22842524350176, 'Mean_Acc1298_Mean_Mem40_Flux': 0.9659478068351746, 'Mean_Acc1298_Std_Mem40_Flux': 0.30737635493278503, 'Std_Acc1298_Mean_Mem40_Flux': 0.1643809676170349, 'Std_Acc1298_Std_Mem40_Flux': 0.049035005271434784}\n"
     ]
    }
   ],
   "source": [
    "#create the features\n",
    "def compute_feature_aggregations(feature_list,feature_name):\n",
    "    feature_array = np.array(feature_list)\n",
    "\n",
    "    chunks = [\n",
    "        feature_array[i:i+mem_size]\n",
    "        for i in range(0, len(feature_array) - mem_size + 1, mem_size)\n",
    "    ]\n",
    "\n",
    "    chunk_means = [np.mean(chunk) for chunk in chunks]\n",
    "    chunk_stds = [np.std(chunk) for chunk in chunks]\n",
    "\n",
    "    results = {\n",
    "        \"Mean_Acc1298_Mean_Mem40_\"+feature_name:float(np.mean(chunk_means)) ,\n",
    "        \"Mean_Acc1298_Std_Mem40_\"+feature_name: float( np.mean(chunk_stds)),\n",
    "        \"Std_Acc1298_Mean_Mem40_\"+feature_name: float( np.std(chunk_means)),\n",
    "        \"Std_Acc1298_Std_Mem40_\"+feature_name:  float( np.std(chunk_stds)),\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "data = {\n",
    "    **compute_feature_aggregations(centroids, \"Centroid\"),\n",
    "    **compute_feature_aggregations(rolloffs, \"Rolloff\"),\n",
    "    **compute_feature_aggregations(flux, \"Flux\"),\n",
    "}\n",
    "\n",
    "for i in range(13):\n",
    "    name = \"MFCC_\"+str(i)\n",
    "    data = {**compute_feature_aggregations(mfccs[i],name), **data}\n",
    "print(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put it all together in a function\n",
    "def compute_feature_aggregations(feature_list,feature_name):\n",
    "    feature_array = np.array(feature_list)\n",
    "\n",
    "    chunks = [\n",
    "        feature_array[i:i+mem_size]\n",
    "        for i in range(0, len(feature_array) - mem_size + 1, mem_size)\n",
    "    ]\n",
    "\n",
    "    chunk_means = [np.mean(chunk) for chunk in chunks]\n",
    "    chunk_stds = [np.std(chunk) for chunk in chunks]\n",
    "\n",
    "    results = {\n",
    "        \"Mean_Acc1298_Mean_Mem40_\"+feature_name:float(np.mean(chunk_means)) ,\n",
    "        \"Mean_Acc1298_Std_Mem40_\"+feature_name: float( np.mean(chunk_stds)),\n",
    "        \"Std_Acc1298_Mean_Mem40_\"+feature_name: float( np.std(chunk_means)),\n",
    "        \"Std_Acc1298_Std_Mem40_\"+feature_name:  float( np.std(chunk_stds)),\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def extract_features_from_wav(filename):\n",
    "    y, sr = librosa.load(filename)\n",
    "    centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "    rolloffs = librosa.feature.spectral_rolloff(y=y, sr=sr, roll_percent=0.85)[0]\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    S = np.abs(librosa.stft(y))\n",
    "    S_norm = librosa.util.normalize(S, axis=0)\n",
    "    flux = np.sqrt(np.sum(np.diff(S_norm, axis=1)**2, axis=0))\n",
    "\n",
    "  \n",
    "    data = {\n",
    "        **compute_feature_aggregations(centroids, \"Centroid\"),\n",
    "        **compute_feature_aggregations(rolloffs, \"Rolloff\"),\n",
    "        **compute_feature_aggregations(flux, \"Flux\"),\n",
    "    }\n",
    "\n",
    "    for i in range(13):\n",
    "        name = \"MFCC_\"+str(i)\n",
    "        data = {**compute_feature_aggregations(mfccs[i],name), **data}\n",
    "\n",
    "#also do it for a bunch of files in a folder\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "def audio_directory_to_df(audio_dir):\n",
    "    files = [f for f in listdir(audio_dir) if f.endswith('.wav')]\n",
    "    data = [extract_features_from_wav(f) for f in files]\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
